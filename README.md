Welcome to my GitHub portfolio! This repository serves as a showcase of my projects and contributions. Feel free to explore and learn more about my work.

## Table of Contents

- [About Me](#about-me)
- [Projects](#projects)
- [Contributions](#contributions)
- [Contact Me](#contact-me)

## About Me

I've dedicated myself to learning data engineering with a passion for several months now, and I find it incredibly rewarding. My path in this field has been shaped by the immersive bootcamp program at Alterra Academy, where I've gained invaluable guidance and knowledge.Briefly introduce yourself here. Mention your background, skills, and interests related to programming or any other relevant information.
- **Data Engineering:** Proficient in various data engineering concepts, including data processing, ETL (Extract, Transform, Load) pipelines, data warehousing, and more.
- **Programming Languages:** Skilled in Python, SQL, and other relevant programming languages for data engineering tasks.
- **Tools and Technologies:** Experienced with tools like Apache Spark, Apache Kafka, Apache Airflow, SQL databases (e.g., PostgreSQL, MySQL), and cloud platforms (e.g., AWS, GCP).
- **Interest:** Deeply interested in exploring advanced data engineering techniques, optimizing data pipelines for scalability and efficiency, and staying updated with the latest trends in the field.

I am enthusiastic about leveraging my skills and knowledge to tackle real-world data challenges and contribute meaningfully to the field of data engineering.

## Projects

Here are some highlights of the projects I've worked on. Each project includes a brief description and a link to the repository.

1. **Capstone Project (Inventory Aging)**
   - Description: In the inventory aging project, I led the orchestration of the Airflow Ingestion Workflow, managing tasks such as configuring Docker, crafting DAG scripts, and overseeing Extract and Load Processes. Collaborating with my team, we utilized DBT for configuring profiles and leveraged Metabase for efficient data visualization. Our objective was to deliver meticulously curated, user-friendly data models tailored specifically for the project, aiming to provide actionable insights for optimizing inventory management and financial performance.
   - Repository Link: [GitHub Repository](https://github.com/ilyaslanang/capstone_project))

2. **Birth Dynamics in Japan**
   - Description: This ongoing project focuses on analyzing birth demographics in Japan by harnessing a dataset obtained through Airbyte, processed via dbt within an Apache Airflow workflow, and visualized using Metabase. Employing an Extract, Load, and Transform (ELT) approach, I oversee the transformation process from raw data to insightful visualizations. By integrating Airbyte for data ingestion, dbt for transformation, and Metabase for visualization within an Apache Airflow workflow, I ensure seamless data processing and visualization, facilitating in-depth analysis of birth demographics in Japan.
   - Repository Link: [GitHub Repository](https://github.com/ilyaslanang/Birth-Demographics)

## Contributions

**Study at Alterra**
   - Description: During my time as a student at Alterra Academy, I actively engaged in various tasks and projects aimed at honing my skills in data engineering. As part of this journey, I created dedicated repositories within our organization's Git for each task, covering a wide range of modules such as data warehousing, basic programming, data ingestion, and specific tools. Some highlights include:
   - 
1. **Basic Programming Tasks**
   - Created repositories to tackle fundamental programming tasks, covering topics such as data structures, algorithms, and problem-solving techniques using Python, SQL, or other relevant languages.

2. **Data Warehouse Module**
   - Developed a repository focusing on data warehousing concepts, including schema design, dimensional modeling, and implementation of data warehouses using tools like Amazon Redshift or Google BigQuery.

3. **Data Ingestion Projects**
   - Established repositories dedicated to data ingestion tasks, involving the extraction and loading of data from various sources into staging areas or data lakes using tools like Apache Kafka, Apache NiFi, or custom scripts.

4. **Specific Tools and Technologies**
   - Set up repositories for exploring specific tools and technologies commonly used in data engineering, such as Apache Spark, Apache Airflow, or Docker, with a focus on practical implementations and hands-on exercises.

These repositories served as comprehensive resources for each module, containing code, documentation, and additional resources to support my learning and showcase my progress as a data engineering student at Alterra Academy.
   - Repository Link: [GitHub Organization](https://github.com/ALTA-DE1-Ilyas-03Jul1999)

## Contact Me

Feel free to reach out to me through the following channels:
- Email: [sinatriailyas@gmail.com](sinatriailyas@gmail.com)
- LinkedIn: [Ilyas Lanang Sinatria](https://www.linkedin.com/in/lanangsinatria/)
